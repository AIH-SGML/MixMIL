{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from torch_scatter import segment_csr as torch_scatter_segment_csr\n",
    "    from torch_scatter import scatter_softmax as torch_scatter_softmax\n",
    "    from torch_scatter import scatter as torch_scatter_scatter\n",
    "    HAS_TORCH_SCATTER = True\n",
    "except ImportError:\n",
    "    HAS_TORCH_SCATTER = False\n",
    "    print(\"torch_scatter not found. Comparisons will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_function(func, *args, num_runs=100):\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        result = func(*args)\n",
    "        torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    return (end_time - start_time) / num_runs, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_csr(src: torch.Tensor, indptr: torch.Tensor, reduce: str = 'sum') -> torch.Tensor:\n",
    "    if reduce not in ['sum', 'mean', 'min', 'max']:\n",
    "        raise ValueError(\"reduce must be one of 'sum', 'mean', 'min', or 'max'\")\n",
    "    \n",
    "    indptr = indptr.squeeze()\n",
    "    segment_lengths = indptr[1:] - indptr[:-1]\n",
    "    index = torch.repeat_interleave(torch.arange(len(segment_lengths), device=src.device), segment_lengths)\n",
    "    \n",
    "    if reduce == 'sum':\n",
    "        out = torch.zeros(len(segment_lengths), *src.shape[1:], device=src.device)\n",
    "        out.scatter_add_(0, index.view(-1, *([1] * (src.dim() - 1))).expand_as(src), src)\n",
    "    elif reduce == 'mean':\n",
    "        out = torch.zeros(len(segment_lengths), *src.shape[1:], device=src.device)\n",
    "        out.scatter_add_(0, index.view(-1, *([1] * (src.dim() - 1))).expand_as(src), src)\n",
    "        out /= segment_lengths.view(-1, *([1] * (src.dim() - 1)))\n",
    "    elif reduce in ['min', 'max']:\n",
    "        out = torch.full((len(segment_lengths), *src.shape[1:]), float('inf') if reduce == 'min' else float('-inf'), device=src.device)\n",
    "        out.scatter_reduce_(0, index.view(-1, *([1] * (src.dim() - 1))).expand_as(src), src, reduce=reduce)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom segment_csr average time: 0.010329 seconds\n",
      "torch_scatter segment_csr average time: 0.035853 seconds\n",
      "torch_scatter scatter average time: 0.009620 seconds\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "# Test and benchmark segment_csr\n",
    "src = torch.randn(1_000_000, 64, device=device)\n",
    "indptr = torch.tensor([0, 200000, 500000, 1000000], device=device)\n",
    "iidx = torch.tensor([0] *indptr[1].item() + [1] * (indptr[2].item() - indptr[1].item()) + [2] *  (indptr[3].item() - indptr[2].item()), device=device)\n",
    "\n",
    "custom_time, custom_result = benchmark_function(segment_csr, src, indptr)\n",
    "print(f\"Custom segment_csr average time: {custom_time:.6f} seconds\")\n",
    "\n",
    "if HAS_TORCH_SCATTER:\n",
    "    torch_scatter_time, torch_scatter_result = benchmark_function(torch_scatter_segment_csr, src, indptr)\n",
    "    print(f\"torch_scatter segment_csr average time: {torch_scatter_time:.6f} seconds\")\n",
    "    \n",
    "    # torch.testing.assert_close(custom_result, torch_scatter_result), \"segment_csr results are not close!\"\n",
    "    # print(\"segment_csr results are close to torch_scatter implementation.\")\n",
    "\n",
    "\n",
    "    torch_scatter_simple_time, torch_scatter_simple_result = benchmark_function(torch_scatter_scatter, src, iidx, 0)\n",
    "    print(f\"torch_scatter scatter average time: {torch_scatter_simple_time:.6f} seconds\")\n",
    "    \n",
    "    # torch.testing.assert_close(custom_result, torch_scatter_simple_result), \"segment_csr results are not close!\"\n",
    "    # print(\"scatter results are close to torch_scatter implementation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_softmax(src: torch.Tensor, index: torch.Tensor, dim_size: int = None) -> torch.Tensor:\n",
    "    if not torch.is_floating_point(src):\n",
    "        raise ValueError('`scatter_softmax` can only be computed over tensors with floating point data types.')\n",
    "\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max().item() + 1\n",
    "\n",
    "    max_value_per_index = torch.zeros(dim_size, device=src.device, dtype=src.dtype)\n",
    "    max_value_per_index.scatter_reduce_(0, index, src, reduce='amax')\n",
    "    max_per_src_element = max_value_per_index.gather(0, index)\n",
    "\n",
    "    recentered_scores = src - max_per_src_element\n",
    "    recentered_scores_exp = recentered_scores.exp()\n",
    "\n",
    "    sum_per_index = torch.zeros(dim_size, device=src.device, dtype=src.dtype)\n",
    "    sum_per_index.scatter_add_(0, index, recentered_scores_exp)\n",
    "    normalizing_constants = sum_per_index.gather(0, index)\n",
    "\n",
    "    return recentered_scores_exp / normalizing_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom scatter_softmax average time: 0.010368 seconds\n",
      "torch_scatter scatter_softmax average time: 0.007084 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test and benchmark scatter_softmax\n",
    "src = torch.randn(1000000, device=device)\n",
    "index = torch.randint(0, 100, (1000000,), device=device)\n",
    "\n",
    "custom_time, custom_result = benchmark_function(scatter_softmax, src, index)\n",
    "print(f\"Custom scatter_softmax average time: {custom_time:.6f} seconds\")\n",
    "\n",
    "if HAS_TORCH_SCATTER:\n",
    "    torch_scatter_time, torch_scatter_result = benchmark_function(torch_scatter_softmax, src, index)\n",
    "    print(f\"torch_scatter scatter_softmax average time: {torch_scatter_time:.6f} seconds\")\n",
    "    \n",
    "    # assert torch.allclose(custom_result, torch_scatter_result, atol=1e-4), \"scatter_softmax results are not close!\"\n",
    "    # print(\"scatter_softmax results are close to torch_scatter implementation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000000]), torch.Size([1000000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_result.shape, torch_scatter_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
